---
layout: post
title: Run nf-core Methylseq pipeline on _P.evermanni_ data
author: Shelly Wanamaker
tags: methylseq nf-core coral E5
---
# Purpose

### This post is related to github issue [# 33](https://github.com/urol-e5/timeseries_molecular/issues/33)

The purpose of this entry is to align EM-seq data to the _P. evermanni_ genome using nf-core pipelines on Klone.

# Results

### EM-seq
- multiqc: [https://gannet.fish.washington.edu/metacarcinus/E5/Ptuahiniensis/20250422_methylseq/multiqc/bismark/multiqc_report.html](https://gannet.fish.washington.edu/metacarcinus/E5/Ptuahiniensis/20250422_methylseq/multiqc/bismark/multiqc_report.html)
- Methylseq output and counts matrices: [https://gannet.fish.washington.edu/metacarcinus/E5/Ptuahiniensis/20250422_methylseq/](https://gannet.fish.washington.edu/metacarcinus/E5/Ptuahiniensis/20250422_methylseq/)

# Methods
### Copy genome files to klone
```
# show path
pwd
/gscratch/srlab/strigg/GENOMES

# copy genome
wget https://gannet.fish.washington.edu/seashell/snaps/Porites_evermanni_v1.fa

#copy gtf file
wget https://github.com/urol-e5/timeseries_molecular/raw/99f0563a067ca9d010cb206dfd44b36d8f77de00/E-Peve/data/Porites_evermanni_validated.gtf


# copy gff file
wget https://github.com/urol-e5/timeseries_molecular/raw/99f0563a067ca9d010cb206dfd44b36d8f77de00/E-Peve/data/Porites_evermanni_validated.gff3

```

### Copy WGBS to klone

```
# open screen session
screen -r methylseq

#make and change into dir

mkdir /gscratch/scrubbed/strigg/analyses/20250529_methylseq/data

cd /gscratch/scrubbed/strigg/analyses/20250529_methylseq/data

# copy data 
rsync --progress --verbose --archive shellytrigg@gannet.fish.washington.edu:/volume2/web/gitrepos/urol-e5/timeseries_molecular/E-Peve/output/01.00-E-Peve-WGBS-trimming-fastp-FastQC-MultiQC .

```

### Run methylseq pipeline
 

```
# start interactive node
salloc -A srlab -p cpu-g2-mem2x -N 1 -c 1 --mem=16GB --time=72:00:00

#activate conda environment
mamba activate nextflow

nextflow run nf-core/methylseq \
-c /gscratch/srlab/strigg/bin/uw_hyak_srlab.config \
--input /gscratch/scrubbed/strigg/analyses/20250529_methylseq/samplesheet.csv \
--outdir /gscratch/scrubbed/strigg/analyses/20250529_methylseq \
--fasta /gscratch/srlab/strigg/GENOMES/Porites_evermanni_v1.fa \
--em_seq \
-resume \
-with-report nf_report.html \
-with-trace \
-with-timeline nf_timeline.html \
--skip_trimming \
--nomeseq 
```


This pipeline completed with errors and didn't process all the samples, seemingly because of memory issues and jobs not getting requeued as they should to the other nodes. I'm in contact with UW IT and Carson Miller at UW Peds about solutions. 

[Multiqc report here](https://gannet.fish.washington.edu/metacarcinus/E5/Pevermanni/20250529_methylseq/multiqc/bismark/multiqc_report.html)

I attempted to rerun the pipline and set the max memory to 400 GB to see if that might help. However, I have a hunch the jobs that failed didn't even get resubmitted to attempt more memory in the first place.

still failed. trying again with the --requeue option excluded. As suggested by Kristen from UW IT:

------------------------------
06/05/2025 11:05 AM PDT - Kristen	Additional Comments
Hey Shelly, 

Thanks for following up. We looked around in the documentation and elsewhere and we think that --requeue will requeue to the same account and partition as initially submitted. We think the --requeue flag in your second config file is in conflict with what you are trying to do. The default behavior for ckpt is that when the time limit is reached, (5:05 for CPU jobs, 8:05 for GPU jobs) the job is requeued and our slurm config for ckpt uses the --requeue flag to do this requeuing to ckpt. 

We think that the NextFlow config is simply resubmitting the job and not a requeue in this sense according to Slurm's definition of requeue. For this reason, we think you should try again without --requeue. 

When you try it out and if you have more question please include the JobIDs and we can help investigate this behavior. 

Thank you, 

Kristen 

06/05/2025 8:08 AM PDT - Shelly	Additional Comments
Hi Kristen,
 
I was able to find a workaround, but I'm running into an issue now with
some jobs that are running over the time limit of ckpt. In the past, these
would not get requeued on ckpt and instead get queued on my lab's node to
get around the time limit. This was all specified in my config file as
follows:
 
``` 
process {
 
errorStrategy = 'retry'
 
maxSubmitAwait = '60 min'
 
maxRetries = 2
 
executor = 'slurm'
 
queue = { task.attempt < 4 ? (task.attempt < 3 ? 'ckpt' : 'cpu-g2' ) :
'cpu-g2-mem2x' }
 
clusterOptions = { task.attempt < 4 ? (task.attempt < 3 ? "-A srlab" :
"-A coenv" ) : "-A srlab" }
 
scratch = '/gscratch/scrubbed/srlab/'
 
resourceLimits = [
 
cpus: 16,
 
memory: '150.GB',
 
time: '72.h'
 
]
 
}
``` 
 
However, when I encountered the issue
with the --no-requeue failing on ckpt, I made the following modifications
to my config file:
 
```
process {
 
errorStrategy = {task.exitStatus in ((130..145)) ? 'ignore' : 'retry'}
 
maxSubmitAwait = '60 min'
 
maxRetries = 2
 
executor = 'slurm'
 
queue = { task.attempt < 4 ? (task.attempt < 3 ? 'ckpt-all' : 'cpu-g2'
) : 'cpu-g2-mem2x' }
 
clusterOptions = { task.attempt < 4 ? (task.attempt < 3 ? "-A srlab
--requeue" : "-A coenv --requeue" ) : "-A srlab --requeue" }
 
scratch = '/gscratch/scrubbed/srlab/'
 
resourceLimits = [
 
cpus: 16,
 
memory: '150.GB',
 
time: '72.h'
 
]
 
 
withName:preseq {
 
errorStrategy = 'ignore'
 
}
``` 
 
And now my jobs are running on ckpt but not being queued on my lab's nodes
when they fail on ckpt due to the time limit. I'm not sure how to resolve
this yet so if you have any ideas, I'm all ears.
 
Thanks,
 
Shelly

----------------------------



In the past this prevented the pipeline from running but maybe it will work this time?

The pipeline completed with errors. Report here: [https://gannet.fish.washington.edu/metacarcinus/E5/Pevermanni/20250605_methylseq/pipeline_info/nf_report.html](https://gannet.fish.washington.edu/metacarcinus/E5/Pevermanni/20250605_methylseq/pipeline_info/nf_report.html)

copied the data to Gannet: 

```
rsync --progress --verbose --archive --exclude bismark/ --exclude work/ --exclude cat/ --exclude data/ 20250605_methylseq shellytrigg@gannet.fish.washington.edu:/volume2/web/metacarcinus/E5/Pevermanni


rsync --progress --verbose --archive multiqc shellytrigg@gannet.fish.washington.edu:/volume2/web/metacarcinus/E5/Pevermanni/20250605_methylseq
```
certain samples still failed and didn't get retried. This is because of the text that was in the config file that specifies if the error exit status is 145 (when the sample takes too long) it is ignored rather than retried. I forgot to revert that section back to how I had it before those updates. 

```
process {
    errorStrategy = { task.exitStatus in ((130..145)) ? 'ignore' : 'retry' }
    maxSubmitAwait = '60 min'
    maxRetries = 2
    executor = 'slurm'
    queue  = { task.attempt < 4 ? (task.attempt < 3 ? 'ckpt-all' : 'cpu-g2' ) : 'cpu-g2-mem2x' }
    clusterOptions = { task.attempt < 4 ? (task.attempt < 3 ? "-A srlab --requeue" : "-A coenv --requeue" ) : "-A srlab --requeue" }
    scratch = '/gscratch/scrubbed/srlab/'
    resourceLimits = [
        cpus: 16,i
        memory: '150.GB',
        time: '72.h'
   ]


```

I reverted the .config file back to the original parameters, retried the pipeline, and it completed ([report here](https://gannet.fish.washington.edu/metacarcinus/E5/Pevermanni/20250605_methylseq/nf_report.html)). I realized in comparing the number of samples that two samples got concatenated because of two errors in my samplesheet. There should be 38 samples and I only had 36 because POR-262-TP3 + TP4 and POR-73-TP3 + TP4 got concatenated. See [multiqc report](https://gannet.fish.washington.edu/metacarcinus/E5/Pevermanni/20250605_methylseq/multiqc/bismark/multiqc_report.html)

I edited the sample sheet and am rerunning the pipeline again. It took 19 hours to complete so should be done by tomorrow.

nextflow run nf-core/methylseq \
-c /gscratch/srlab/strigg/bin/uw_hyak_srlab.config \
--input /gscratch/scrubbed/strigg/analyses/20250619_methylseq/samplesheet.csv \
--outdir /gscratch/scrubbed/strigg/analyses/20250619_methylseq \
--fasta /gscratch/srlab/strigg/GENOMES/Porites_evermanni_v1.fa \
--em_seq \
-resume \
-with-report nf_report.html \
-with-trace \
-with-timeline nf_timeline.html \
--skip_trimming \
--nomeseq 
